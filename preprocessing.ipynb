{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fc341fe-5014-458d-a544-0995b439f344",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-29 15:16:42.500048: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6d03212-2507-46cc-9485-bca89a8900f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_size = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372aca3f-3aa6-4529-9746-6b18af270846",
   "metadata": {
    "id": "dSH9HMlbfTpk",
    "tags": []
   },
   "source": [
    "# A closer look at our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41aea35b-10f5-4386-aa6c-ea98242b25d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_path</th>\n",
       "      <th>Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_4513976.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_7764995.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_451308.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_7768372.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_7765274.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image_path  Condition\n",
       "0  img_4513976.jpg          0\n",
       "1  img_7764995.jpg          1\n",
       "2   img_451308.jpg          0\n",
       "3  img_7768372.jpg          1\n",
       "4  img_7765274.jpg          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = pd.read_csv(\"data/raw_data/labels.csv\")\n",
    "label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6c11571-dfa4-487e-8c1e-625a5fbb8e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1399 entries, 0 to 1398\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Image_path  1399 non-null   object\n",
      " 1   Condition   1399 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 22.0+ KB\n"
     ]
    }
   ],
   "source": [
    "label.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c7260f0-bef1-41ae-b1a9-d0e9478ff37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate percentage of damaged cars\n",
    "round(sum(label[\"Condition\"]) / label.shape[0], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ecc662-7c82-4fea-885d-449cc8c1d752",
   "metadata": {},
   "source": [
    "* To address the issue of imbalanced data, we will create a balanced validation set by selecting 20 images each of damaged and good condition. Additionally, we will utilize image augmentation techniques on our training image data to further balance the training data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab83aaa-71f8-4da3-ab56-a0f97726e8f3",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "911ad133-d2b9-41dc-afdb-edf1126d9156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data,valid_size,if_train, seed= 123):\n",
    "    \"\"\"\n",
    "    The split function is used to divide a dataset into a training and validation set. \n",
    "    To ensure that the damaged conditions are represented equally in test sets, \n",
    "    the function takes into account the imbalanced nature of the data. \n",
    "    The function takes in four parameters: the path of the original dataset,\n",
    "    the test size we desire, a flag indicating whether the output is for training or validation, \n",
    "    and a seed for reproducibility. It returns the appropriate training or validation dataset.\n",
    "    \"\"\" \n",
    "    class_damaged_size_ratio = (valid_size/2)/ sum(data['Condition'])\n",
    "    class_undamged_valid_size_ratio = (valid_size/2)/ sum(data['Condition'] == 0)\n",
    "    damaged = data[data.Condition == 1]\n",
    "    undamaged = data[data.Condition == 0]\n",
    "    train_damaged, test_damaged = train_test_split(damaged, test_size=class_damaged_size_ratio , random_state=seed) # for Reproducibility\n",
    "    train_undamaged, test_undamaged = train_test_split(undamaged, test_size=class_undamged_valid_size_ratio , random_state=seed) # for Reproducibility\n",
    "    if if_train:\n",
    "        return pd.concat([train_damaged,train_undamaged])\n",
    "    else:\n",
    "        return pd.concat([test_damaged,test_undamaged])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "324a25b7-4638-4a4a-bc41-a552b31c51ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation class ratio: 1.0\n"
     ]
    }
   ],
   "source": [
    "train = split(label,valid_size,if_train = True)\n",
    "validation = split(label,valid_size,if_train = False)\n",
    "print(f'validation class ratio: {sum(validation[\"Condition\"])/sum(validation[\"Condition\"] == 0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdf205fa-97df-4a87-81ea-5bad13f1a2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been processed\n"
     ]
    }
   ],
   "source": [
    "def move_image(raw_data_folder,label,damaged_folder,non_damaged_folder):\n",
    "    '''\n",
    "    move validation image data to given folders\n",
    "    '''\n",
    "    if len(os.listdir(damaged_folder)) + len(os.listdir(non_damaged_folder)) == 0:\n",
    "        for index in range(len(label)):\n",
    "            raw_img_path = os.path.join(raw_data_folder, label.iloc[index, 0])\n",
    "            image = Image.open(raw_img_path)\n",
    "            if label.iloc[index, 1] == 1:\n",
    "                damaged_path = os.path.join(damaged_folder,label.iloc[index, 0])\n",
    "                image.save(damaged_path)\n",
    "            else:\n",
    "                non_damaged_path = os.path.join(non_damaged_folder,label.iloc[index, 0])\n",
    "                image.save(non_damaged_path)\n",
    "    else:\n",
    "        print('Data has been processed')\n",
    "        \n",
    "        \n",
    "raw_data_folder = 'data/raw_data/Images'\n",
    "damaged_folder = 'data/processed_data/valid/damaged'\n",
    "non_damaged_folder = 'data/processed_data/valid/non-damaged'\n",
    "move_image(raw_data_folder,validation,damaged_folder,non_damaged_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc72c60d-7e92-4964-be18-8107fbc89bb1",
   "metadata": {},
   "source": [
    "# Generate new images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64c31d28-e5d3-46be-aa04-df5357021a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image augmentation function\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddb048f8-52bc-478c-8023-c57163bf0176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repulicate(raw_data_folder,label,n_replicates,damaged_folder,non_damaged_folder):\n",
    "    '''\n",
    "    generate images and move training image data to given folders.\n",
    "    '''\n",
    "    if len(os.listdir(damaged_folder)) + len(os.listdir(non_damaged_folder)) == 0:\n",
    "        for index in range(len(label)):\n",
    "            raw_img_path = os.path.join(raw_data_folder, label.iloc[index, 0])\n",
    "            image = Image.open(raw_img_path)\n",
    "            if label.iloc[index, 1] == 1:\n",
    "                damaged_path = os.path.join(damaged_folder,label.iloc[index, 0])\n",
    "                image.save(damaged_path)\n",
    "            else:\n",
    "                image_tensor = img_to_array(image)\n",
    "                image_tensor = image_tensor.reshape((1,) + image_tensor.shape)\n",
    "                i = 0\n",
    "                for batch in datagen.flow(image_tensor, batch_size=1,save_to_dir=non_damaged_folder, save_prefix='aug', save_format='jpg'):\n",
    "                    i += 1\n",
    "                    if i > n_replicates:\n",
    "                        break  \n",
    "    else:\n",
    "        print('Data has been processed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67cc1796-0ecb-40b1-b3fd-424cf5112378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data class ratio: 1.01 \n"
     ]
    }
   ],
   "source": [
    "n_replicates = round(sum(train[\"Condition\"]) / sum(train[\"Condition\"] == 0)) \n",
    "raw_data_folder = 'data/raw_data/Images'\n",
    "damaged_folder = 'data/processed_data/train/damaged'\n",
    "non_damaged_folder = 'data/processed_data/train/non-damaged'\n",
    "repulicate(raw_data_folder,train,n_replicates,damaged_folder,non_damaged_folder )\n",
    "print(f'training data class ratio: {round(len(os.listdir(damaged_folder))/len(os.listdir(non_damaged_folder)),2)} ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bd6b96-8dbf-479b-b811-184d1cebfca1",
   "metadata": {},
   "source": [
    "* Now we have a balanced training and validation data set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsci572]",
   "language": "python",
   "name": "conda-env-dsci572-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
